{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35d2a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e44910",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a259f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>filename</th>\n",
       "      <th>sound_prediction_score</th>\n",
       "      <th>tb_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088710003-recording-1.wav</td>\n",
       "      <td>0.990254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088760390-recording-1.wav</td>\n",
       "      <td>0.990272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088760830-recording-1.wav</td>\n",
       "      <td>0.990112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088710843-recording-1.wav</td>\n",
       "      <td>0.990152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088759950-recording-1.wav</td>\n",
       "      <td>0.990039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088758630-recording-1.wav</td>\n",
       "      <td>0.990004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088758230-recording-1.wav</td>\n",
       "      <td>0.975063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088738844-recording-1.wav</td>\n",
       "      <td>0.990068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088784942-recording-1.wav</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088784542-recording-1.wav</td>\n",
       "      <td>0.990288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant                       filename  sound_prediction_score  \\\n",
       "0  CODA_TB_0001  1645088710003-recording-1.wav                0.990254   \n",
       "1  CODA_TB_0001  1645088760390-recording-1.wav                0.990272   \n",
       "2  CODA_TB_0001  1645088760830-recording-1.wav                0.990112   \n",
       "3  CODA_TB_0001  1645088710843-recording-1.wav                0.990152   \n",
       "4  CODA_TB_0001  1645088759950-recording-1.wav                0.990039   \n",
       "5  CODA_TB_0001  1645088758630-recording-1.wav                0.990004   \n",
       "6  CODA_TB_0001  1645088758230-recording-1.wav                0.975063   \n",
       "7  CODA_TB_0001  1645088738844-recording-1.wav                0.990068   \n",
       "8  CODA_TB_0001  1645088784942-recording-1.wav                0.990291   \n",
       "9  CODA_TB_0001  1645088784542-recording-1.wav                0.990288   \n",
       "\n",
       "   tb_status  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  \n",
       "6          0  \n",
       "7          0  \n",
       "8          0  \n",
       "9          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a7e536d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13684\n",
       "1    13684\n",
       "Name: tb_status, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['tb_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2940a0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27368 entries, 0 to 27367\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   participant             27368 non-null  object \n",
      " 1   filename                27368 non-null  object \n",
      " 2   sound_prediction_score  27368 non-null  float64\n",
      " 3   tb_status               27368 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 855.4+ KB\n"
     ]
    }
   ],
   "source": [
    "metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad40959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dataset_path = 'time/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b5303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file, res_type = \"kaiser_fast\")\n",
    "    mfccs_features = librosa.feature.mfcc(y = audio, sr = sample_rate, n_mfcc = 40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T, axis = 0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84729d0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27368it [04:45, 95.76it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "extracted_features = []\n",
    "for index_num, row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path), str(row['filename']))\n",
    "    final_class_labels = row['tb_status']\n",
    "    data = features_extractor(file_name)\n",
    "    extracted_features.append([data, final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75ccd21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "for i, (data, final_class_labels) in enumerate(extracted_features):\n",
    "    if isinstance(data, np.ndarray):\n",
    "        extracted_features[i][0] = data.tolist()\n",
    "features_dict = {\n",
    "    'extracted_features': extracted_features\n",
    "}\n",
    "# Specify the output JSON file path\n",
    "output_file_path = 'extracted_features.json'\n",
    "\n",
    "# Write the dictionary to the JSON file\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(features_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79a1588f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tb_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-233.81036, 60.20778, 13.185232, 28.068928, 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-227.28358, 66.7835, 26.548656, 14.419969, -8...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-291.94742, 61.165333, 36.86478, 11.336239, -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-322.38007, 53.536182, 30.724964, 25.726463, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-215.52008, 58.5044, 26.074524, 0.0006127791,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  tb_status\n",
       "0  [-233.81036, 60.20778, 13.185232, 28.068928, 2...          0\n",
       "1  [-227.28358, 66.7835, 26.548656, 14.419969, -8...          0\n",
       "2  [-291.94742, 61.165333, 36.86478, 11.336239, -...          0\n",
       "3  [-322.38007, 53.536182, 30.724964, 25.726463, ...          0\n",
       "4  [-215.52008, 58.5044, 26.074524, 0.0006127791,...          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df = pd.DataFrame(extracted_features, columns = ['feature', 'tb_status'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6a02c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df['feature'][0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03cf1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(extracted_features_df['feature'].tolist())\n",
    "y = np.array(extracted_features_df['tb_status'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b99289d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27368, 40)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37a187af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27368,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5792c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "y = to_categorical(y, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19c373a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27368, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ef2c449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f492aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15d3a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21894, 40)   (5474, 40)\n",
      "(21894, 2)   (5474, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, \" \", X_test.shape)\n",
    "print(y_train.shape, \" \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfd8a4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21894, 8, 5, 1)   (5474, 8, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 8, 5, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 8, 5, 1)\n",
    "print(X_train.shape, \" \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83825da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (8, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4e72034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb36ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', input_shape = input_dim))\n",
    "model.add(MaxPooling2D((1, 1)))\n",
    "\n",
    "model.add(Conv2D(64, (2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D((1, 1)))\n",
    "\n",
    "model.add(Conv2D(128, (2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D((1, 1)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ce2c917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 7, 4, 32)          160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 7, 4, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 3, 64)          8256      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 3, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 5, 2, 128)         32896     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 2, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               655872    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 698,210\n",
      "Trainable params: 698,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13d0cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(learning_rate=0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48872eaf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "616/616 [==============================] - 4s 7ms/step - loss: 0.0277 - accuracy: 0.9929 - val_loss: 0.0392 - val_accuracy: 0.9877\n",
      "Epoch 2/10\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.0134 - val_accuracy: 0.9941\n",
      "Epoch 3/10\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.0285 - val_accuracy: 0.9900\n",
      "Epoch 4/10\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0404 - val_accuracy: 0.9909\n",
      "Epoch 5/10\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0255 - accuracy: 0.9926 - val_loss: 0.0153 - val_accuracy: 0.9959\n",
      "Epoch 6/10\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.0234 - val_accuracy: 0.9932\n",
      "Epoch 7/10\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 0.0302 - val_accuracy: 0.9918\n",
      "Epoch 8/10\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0326 - accuracy: 0.9924 - val_loss: 0.0264 - val_accuracy: 0.9950\n",
      "Epoch 9/10\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.0238 - val_accuracy: 0.9936\n",
      "Epoch 10/10\n",
      "616/616 [==============================] - 4s 6ms/step - loss: 0.0305 - accuracy: 0.9921 - val_loss: 0.0495 - val_accuracy: 0.9854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20057757550>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "num_batch_size = 32\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath = 'saved_models/audio_classification.hdf5',\n",
    "#                                verbose=1, save_best_only = True)\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath = 'saved_model/cnnmodel',\n",
    "#                                verbose=1, save_best_only = True)\n",
    " \n",
    "start = datetime.now()\n",
    "\n",
    "# model.fit(X_train, y_train, batch_size = num_batch_size, epochs = num_epochs, validation_data = (X_test, y_test),   verbose=1)\n",
    "model.fit(X_train, y_train, batch_size = num_batch_size, epochs = num_epochs, validation_split=0.1,   verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca3daca1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 99.51128363609314\n",
      "Loss : 1.7279865220189095\n",
      "Test Accuracy : 95.72524428367615\n",
      "Loss : 24.675342440605164\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Train Accuracy :\",train_accuracy[1] * 100)\n",
    "print(\"Loss :\",train_accuracy[0] * 100)\n",
    "\n",
    "test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy :\",test_accuracy[1] * 100)\n",
    "print(\"Loss :\",test_accuracy[0] * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "937b7037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filename=\"testing/p1.wav\"\n",
    "# audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "# mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=128)\n",
    "# mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "# print(mfccs_scaled_features)\n",
    "# mfccs_scaled_features=mfccs_scaled_features.reshape(1, 128, 1, 1)\n",
    "# print(mfccs_scaled_features)\n",
    "# print(mfccs_scaled_features.shape)\n",
    "\n",
    "# predicted_label=np.argmax(model.predict(mfccs_scaled_features), axis=-1)\n",
    "# print(predicted_label)\n",
    "# prediction_class = labelencoder.inverse_transform(predicted_label) \n",
    "# prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed171be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n",
      "[1]\n",
      "TB Positive\n"
     ]
    }
   ],
   "source": [
    "filename=\"test3.wav\"\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "mfccs_scaled_features = np.repeat(mfccs_scaled_features, 1, axis=0)\n",
    "\n",
    "# print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1, 8, 5, 1)\n",
    "# print(mfccs_scaled_features)\n",
    "# print(mfccs_scaled_features.shape)\n",
    "\n",
    "predicted_label=np.argmax(model.predict(mfccs_scaled_features), axis=-1)\n",
    "print(predicted_label)\n",
    "if predicted_label[0] == 1:\n",
    "    print(\"TB Positive\")\n",
    "else:\n",
    "    print(\"TB Negative\")\n",
    "# labelencoder = LabelEncoder()\n",
    "# prediction_class = labelencoder.inverse_transform(predicted_label) \n",
    "# prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18c5a9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_mfcc_10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_mfcc_10\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('cnn_mfcc_10')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
