{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cffb422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb4bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('original.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef62742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>filename</th>\n",
       "      <th>sound_prediction_score</th>\n",
       "      <th>tb_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088710003-recording-1.wav</td>\n",
       "      <td>0.990254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088760390-recording-1.wav</td>\n",
       "      <td>0.990272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088760830-recording-1.wav</td>\n",
       "      <td>0.990112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088710843-recording-1.wav</td>\n",
       "      <td>0.990152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088759950-recording-1.wav</td>\n",
       "      <td>0.990039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088758630-recording-1.wav</td>\n",
       "      <td>0.990004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088758230-recording-1.wav</td>\n",
       "      <td>0.975063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088738844-recording-1.wav</td>\n",
       "      <td>0.990068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088784942-recording-1.wav</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CODA_TB_0001</td>\n",
       "      <td>1645088784542-recording-1.wav</td>\n",
       "      <td>0.990288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant                       filename  sound_prediction_score  \\\n",
       "0  CODA_TB_0001  1645088710003-recording-1.wav                0.990254   \n",
       "1  CODA_TB_0001  1645088760390-recording-1.wav                0.990272   \n",
       "2  CODA_TB_0001  1645088760830-recording-1.wav                0.990112   \n",
       "3  CODA_TB_0001  1645088710843-recording-1.wav                0.990152   \n",
       "4  CODA_TB_0001  1645088759950-recording-1.wav                0.990039   \n",
       "5  CODA_TB_0001  1645088758630-recording-1.wav                0.990004   \n",
       "6  CODA_TB_0001  1645088758230-recording-1.wav                0.975063   \n",
       "7  CODA_TB_0001  1645088738844-recording-1.wav                0.990068   \n",
       "8  CODA_TB_0001  1645088784942-recording-1.wav                0.990291   \n",
       "9  CODA_TB_0001  1645088784542-recording-1.wav                0.990288   \n",
       "\n",
       "   tb_status  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  \n",
       "6          0  \n",
       "7          0  \n",
       "8          0  \n",
       "9          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709482ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13684\n",
       "1    13684\n",
       "Name: tb_status, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['tb_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44eb4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dataset_path = 'time/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2918815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file, res_type = \"kaiser_fast\")\n",
    "    mfccs_features = librosa.feature.mfcc(y = audio, sr = sample_rate, n_mfcc = 40)\n",
    "#     mfccs_scaled_features = np.mean(mfccs_features.T, axis = 0)\n",
    "    mfccs_array = np.array(mfccs_features)\n",
    "    mfccs_image = Image.fromarray(mfccs_array).resize((32,32))\n",
    "    \n",
    "    \n",
    "    return np.array(mfccs_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce2f74a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27368it [04:13, 108.15it/s]\n"
     ]
    }
   ],
   "source": [
    "extracted_features = []\n",
    "for index_num, row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path), str(row['filename']))\n",
    "    final_class_labels = row['tb_status']\n",
    "    data = features_extractor(file_name)\n",
    "    extracted_features.append([data, final_class_labels])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9808626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "for i, (data, final_class_labels) in enumerate(extracted_features):\n",
    "    if isinstance(data, np.ndarray):\n",
    "        extracted_features[i][0] = data.tolist()\n",
    "features_dict = {\n",
    "    'extracted_features': extracted_features\n",
    "}\n",
    "# Specify the output JSON file path\n",
    "output_file_path = 'extracted_features_resnet.json'\n",
    "\n",
    "# Write the dictionary to the JSON file\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(features_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0784dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tb_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-330.8592224121094, -337.03973388671875, -35...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-301.1387939453125, -313.8829650878906, -337...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-390.083251953125, -375.6857604980469, -365....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-425.3885498046875, -411.5791015625, -399.65...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-398.68280029296875, -386.0237731933594, -37...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  tb_status\n",
       "0  [[-330.8592224121094, -337.03973388671875, -35...          0\n",
       "1  [[-301.1387939453125, -313.8829650878906, -337...          0\n",
       "2  [[-390.083251953125, -375.6857604980469, -365....          0\n",
       "3  [[-425.3885498046875, -411.5791015625, -399.65...          0\n",
       "4  [[-398.68280029296875, -386.0237731933594, -37...          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df = pd.DataFrame(extracted_features, columns = ['feature', 'tb_status'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05b67c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_features_df['feature'][0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f2b26ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(extracted_features_df['feature'].tolist())\n",
    "y = np.array(extracted_features_df['tb_status'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c93cc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27368, 32, 32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c8cfab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "y = to_categorical(y, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14afea23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27368, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f468713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f78dde50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21894, 32, 32)   (5474, 32, 32)\n",
      "(21894, 2)   (5474, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, \" \", X_test.shape)\n",
    "print(y_train.shape, \" \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a164d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21894, 32, 32, 1)   (5474, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(21894, 32, 32, 1)\n",
    "X_test = X_test.reshape(5474, 32, 32, 1)\n",
    "print(X_train.shape, \" \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45005b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b28bc7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8864cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(include_top = False,\n",
    "        input_shape = input_dim,\n",
    "        pooling = 'avg', classes = 2,\n",
    "        weights = None)\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d355faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(resnet)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a26d3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23581440  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,631,554\n",
      "Trainable params: 1,050,114\n",
      "Non-trainable params: 23,581,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78ef4e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(learning_rate=0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0badfa72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "616/616 [==============================] - 33s 53ms/step - loss: 0.6216 - accuracy: 0.6519 - val_loss: 0.5871 - val_accuracy: 0.6909\n",
      "Epoch 2/20\n",
      "616/616 [==============================] - 32s 52ms/step - loss: 0.6165 - accuracy: 0.6619 - val_loss: 0.5891 - val_accuracy: 0.6904\n",
      "Epoch 3/20\n",
      "616/616 [==============================] - 32s 52ms/step - loss: 0.6136 - accuracy: 0.6653 - val_loss: 0.5988 - val_accuracy: 0.6854\n",
      "Epoch 4/20\n",
      "616/616 [==============================] - 33s 53ms/step - loss: 0.6112 - accuracy: 0.6636 - val_loss: 0.5861 - val_accuracy: 0.6909\n",
      "Epoch 5/20\n",
      "616/616 [==============================] - 33s 53ms/step - loss: 0.6139 - accuracy: 0.6623 - val_loss: 0.5807 - val_accuracy: 0.6868\n",
      "Epoch 6/20\n",
      "616/616 [==============================] - 33s 54ms/step - loss: 0.6107 - accuracy: 0.6665 - val_loss: 0.5974 - val_accuracy: 0.6904\n",
      "Epoch 7/20\n",
      "616/616 [==============================] - 33s 53ms/step - loss: 0.6054 - accuracy: 0.6688 - val_loss: 0.5811 - val_accuracy: 0.6932\n",
      "Epoch 8/20\n",
      "616/616 [==============================] - 33s 54ms/step - loss: 0.6104 - accuracy: 0.6668 - val_loss: 0.5875 - val_accuracy: 0.6968\n",
      "Epoch 9/20\n",
      "616/616 [==============================] - 33s 54ms/step - loss: 0.6034 - accuracy: 0.6724 - val_loss: 0.5922 - val_accuracy: 0.6776\n",
      "Epoch 10/20\n",
      "616/616 [==============================] - 33s 53ms/step - loss: 0.6048 - accuracy: 0.6730 - val_loss: 0.5773 - val_accuracy: 0.6941\n",
      "Epoch 11/20\n",
      "616/616 [==============================] - 33s 53ms/step - loss: 0.6012 - accuracy: 0.6724 - val_loss: 0.5718 - val_accuracy: 0.7073\n",
      "Epoch 12/20\n",
      "616/616 [==============================] - 32s 52ms/step - loss: 0.6010 - accuracy: 0.6718 - val_loss: 0.5711 - val_accuracy: 0.6945\n",
      "Epoch 13/20\n",
      "616/616 [==============================] - 32s 53ms/step - loss: 0.5984 - accuracy: 0.6732 - val_loss: 0.5797 - val_accuracy: 0.7050\n",
      "Epoch 14/20\n",
      "616/616 [==============================] - 33s 54ms/step - loss: 0.6028 - accuracy: 0.6782 - val_loss: 0.5683 - val_accuracy: 0.7005\n",
      "Epoch 15/20\n",
      "616/616 [==============================] - 33s 53ms/step - loss: 0.5968 - accuracy: 0.6822 - val_loss: 0.5723 - val_accuracy: 0.7073\n",
      "Epoch 16/20\n",
      "616/616 [==============================] - 33s 53ms/step - loss: 0.5983 - accuracy: 0.6737 - val_loss: 0.5646 - val_accuracy: 0.7005\n",
      "Epoch 17/20\n",
      "616/616 [==============================] - 33s 54ms/step - loss: 0.5958 - accuracy: 0.6790 - val_loss: 0.5640 - val_accuracy: 0.7018\n",
      "Epoch 18/20\n",
      "616/616 [==============================] - 33s 53ms/step - loss: 0.5929 - accuracy: 0.6789 - val_loss: 0.5658 - val_accuracy: 0.7059\n",
      "Epoch 19/20\n",
      "616/616 [==============================] - 33s 54ms/step - loss: 0.5981 - accuracy: 0.6724 - val_loss: 0.5671 - val_accuracy: 0.7068\n",
      "Epoch 20/20\n",
      "616/616 [==============================] - 33s 54ms/step - loss: 0.5903 - accuracy: 0.6811 - val_loss: 0.5820 - val_accuracy: 0.7032\n",
      "Training completed in time :  0:10:56.345663\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "num_epochs = 20\n",
    "num_batch_size = 32\n",
    "\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size = num_batch_size, epochs = num_epochs, validation_split=0.1, verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "\n",
    "print(\"Training completed in time : \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff8de5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685/685 [==============================] - 32s 47ms/step - loss: 0.5834 - accuracy: 0.7020\n",
      "Train Loss: 0.5833548903465271\n",
      "Train Accuracy: 0.7020187973976135\n",
      "172/172 [==============================] - 8s 46ms/step - loss: 0.5835 - accuracy: 0.7072\n",
      "Test Loss: 0.5834708213806152\n",
      "Test Accuracy: 0.7071611285209656\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print(\"Train Loss:\", loss)\n",
    "print(\"Train Accuracy:\", accuracy)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d94b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"solicited/1654077922741-recording-1.wav\"\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "# mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "# mfccs_scaled_features = np.repeat(mfccs_scaled_features, 1, axis=0)\n",
    "\n",
    "#print(mfccs_scaled_features)\n",
    "# mfccs_scaled_features=mfccs_scaled_features.reshape(1, 32, 32, 1)\n",
    "mfccs_array = np.array(mfccs_features)\n",
    "mfccs_image = Image.fromarray(mfccs_array).resize((32,32))\n",
    "mfccs_scaled_features = np.array(mfccs_image)\n",
    "print(mfccs_scaled_features)\n",
    "print(mfccs_scaled_features.shape)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1, 32, 32, 1)\n",
    "\n",
    "predicted_label=np.argmax(model.predict(mfccs_scaled_features), axis=-1)\n",
    "print(predicted_label)\n",
    "if predicted_label[0] == 1:\n",
    "    print(\"TB Positive\")\n",
    "else:\n",
    "    print(\"TB Negative\")\n",
    "# labelencoder = LabelEncoder()\n",
    "# prediction_class = labelencoder.inverse_transform(predicted_label) \n",
    "# prediction_class\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
